---
title: "2023 UPDATE to Bay Area Conservation & Development Commission Vulnerable Communities Data (2020)"
author: "Adapting to Rising Tides: Nicolas Sander, Todd Hallenbeck & Elizabeth Felter"
date of update: "April 25, 2023"
date published: "July 13th, 2020"
output: rmarkdown::github_document
editor_options: 
  chunk_output_type: console
---
# Setup R, Install + Load Required Packages
```{r Library, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

remove(list = ls(all.names = TRUE))
detachAllPackages <- function() {
  basic.packages.blank <-  c("stats", 
                             "graphics", 
                             "grDevices", 
                             "utils", 
                             "datasets", 
                             "methods", 
                             "base")
  basic.packages <- paste("package:", basic.packages.blank, sep = "")

  package.list <- search()[ifelse(unlist(gregexpr("package:", search())) == 1, 
                                  TRUE, 
                                  FALSE)]

  package.list <- setdiff(package.list, basic.packages)

  if (length(package.list) > 0)  for (package in package.list) {
    detach(package, character.only = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}
detachAllPackages()

using<-function(...) {
    libs<-unlist(list(...))
    req<-unlist(lapply(libs,require,character.only=TRUE))
    need<-libs[req==FALSE]
    if(length(need)>0){ 
        install.packages(need)
        lapply(need,require,character.only=TRUE)
    }
}
extrafont::loadfonts(device="win")
using("tidycensus","tidyverse","viridis","tigris","mapview","sf","leaflet","arcgisbinding","RCurl","downloader")
options(tigris_use_cache = TRUE)
arc.check_product()
```

# Census API Key (should be hidden!)
```{r Census API Key, include=FALSE}
# install Census API key (obtained from http://api.census.gov/data/key_signup.html)
#Enter a free Census API Key
censusapikey <- rstudioapi::askForPassword()
census_api_key(censusapikey, install=T)
readRenviron("~/.Renviron")
```

# Setting Global Variable such as "Year" and "County Codes"
```{r Global Variables}
# Last year of current 5 year ACS data
year <- as.numeric(rstudioapi::showPrompt("ACS End Year", "Type the last year of the ACS dataset you wish to use", default = 2018))
#year <- 2018
#year <- 2016 #testing with old data
# FIPS codes of all 9 Bay Area Counties
bayareacounties <- c("001","013","041","055","075","081","085","095","097")
```

# Table of all ACS Variables
```{r Load all ACS5 tables for inspection}
# loading all available 5-year ACS variables for inspection in a table
v18 <- load_variables(year, "acs5", cache = TRUE)
```

# Functions for making life easier
```{r bcdc_get_acs function for 9 Bay Area Counties}
bcdc_get_acs <- function(x, geography = "block group"){
  get_acs(geography = geography,
          variables = unlist(x[4]),
          state = "CA",
          county = bayareacounties,
          summary_var = unlist(x[5]),
          year = year,
          geometry = F
          ) %>% 
    mutate(variable = unlist(x[1])) %>%
    mutate(alias = unlist(x[2])) %>%
    mutate(universe = unlist(x[3]))
}
```

```{r vulnflag function}
#Combines variables, calculates percentage of table totals, percentage's margin of error, the 70th and 90th percentile and flags block groups that cross the percentile thresholds

vulnflag <- function(data){
        data %>%
        # filter out any GEOIDs from the removebgs object with <100 totPop & totHH
        filter(!(GEOID %in% removebgs$GEOID)) %>%
        # group the data by everything, except for the estimate and estimate's margin of error
        group_by(GEOID, NAME, summary_est, summary_moe, alias, universe) %>%
        # sum the estimates of variables, square root of the sum of squared margins of error, create variable name column
        summarise(variable = variable[1], estimate = sum(estimate), moe = sqrt(sum(moe^2))) %>%
        # calculate the estimate as percent of total (if total does not equal 0)
        mutate(pct = ifelse(summary_est != 0, estimate/summary_est*100, 0)) %>%
        # calculate the estimate's margin of error of the percentage,
        # IF margin of error is larger than the product of the percentage and summary estimate's margin of error:
        mutate(pct_moe = ifelse(moe > (pct * summary_moe),
          # THEN: square root of the squared margin of error minus the product of the squared percentage and squared summary estimate,
          # divided by the summary estimate
          sqrt(moe^2 - pct^2 * summary_moe^2)/summary_est,
          # ELSE: square root of the squared margin of error plus the product of the squared percentage and squared summary estimate,
          # divided by the summary estimate
          sqrt(moe^2 + pct^2 * summary_moe^2)/summary_est
          )) %>%
        # group by variable, so that percentiles are calculated for the entire region
        ungroup() %>% group_by(variable) %>%
        # calculate 70th percentile
        mutate(pctile70 = quantile(pct, 0.7, na.rm = T)) %>%
        # calculate 90th percentile
        mutate(pctile90 = quantile(pct, 0.9, na.rm = T)) %>%
        # flag if percentage is above 70th percentile
        mutate(flag70 = ifelse(pct >= pctile70, 1, 0)) %>%
        # flag if percentage is above 90th percentile
        mutate(flag90 = ifelse(pct >= pctile90, 1, 0)) %>% ungroup()
}
```

# Empty Geographies to get Join IDs
```{r Empty Geographies for Joining}
# pulling arbitrary ACS table, removing variable, to obtain identical block group data structure
emptyblockgroups <-  get_acs(
          geography = "block group",
          variables = "B01001_001",
          state = "CA",
          county = bayareacounties,
          year = year,
          geometry = T
          ) %>% 
    select(-variable, -estimate, -moe) %>% st_transform(26910)


# pulling arbitrary ACS table, removing variable, to obtain identical tract data structure
emptytracts <-  get_acs(
          geography = "tract",
          variables = "B01001_001",
          state = "CA",
          county = bayareacounties,
          year = year,
          geometry = T
          ) %>% 
    select(-variable, -estimate, -moe) %>% st_transform(26910)

# attach tract ID for joining additional data
emptyblockgroups <- st_join(emptyblockgroups, select(emptytracts, TRACTID = GEOID), left_join = T, largest = T)
```

# Removes block group areas over water, e.g. piers. (Note:the output is already pre-calculated in "Inputs" and loaded in)
```{r Remove areas over water with TIGER data, eval=F}
# Erase function for deleting polygon edges that reach into the water
st_erase <- function(x, y) {
  st_difference(x, st_union(y))
}

# Creating water layer for the 9 Bay Area Counties
county_water <- list()
for(x in bayareacounties){
county_water[[x]] <- area_water("CA",x, class= "sf")
}
bcdc_water <- do.call(rbind, county_water)
bcdc_water_transformed <- st_transform(bcdc_water, st_crs(emptyblockgroups))

# Erase water
bg_nowater <- st_erase(emptyblockgroups, bcdc_water_transformed)

arcgisbinding::arc.write(paste0(getwd(),"/Inputs/bg_nowater.shp"), bg_nowater, validate = T)
```

# All Indicators used in BCDC Vulnerability Ranking
```{r Total Population, Total HHs, Average HH Size, Median HH Income}
vars <- list(
             c(name = "totPop", alias = "Total Population", universe = "Population", variable = I(list(c("B01003_001")))),
             c(name = "totHH", alias = "Total Households", universe = "Occupied housing units", variable = I(list(c("B25003_001")))),
             c(name = "AveHHSize", alias = "Average Household Size", universe = "Occupied housing units", variable = I(list(c("B25010_001"))))
             )
             
# Median HH Income not available by block group
#c(name = "MedianHHInc", alias = "Median Household Income", universe = "Households", variable = I(list(c("B19019_001"))))

# for each variable combination (vars) perform the bcdc_get_acs and save as a list entry in datalist
datalist <- lapply(vars, function(x) bcdc_get_acs(x))

# bind all datalist entries (one for each variable) together by row
data <- do.call(rbind, datalist)
# remove datalist
rm(datalist)

# find out block groups with <100 totPop or totHH
removebgs <- data %>% filter((variable == "totPop" & estimate < 100 | variable == "totHH" & estimate < 100))
```

```{r Data (Block Group)}
# listing of all BCDC variable combinations: 1) abbreviated name 2) common variable name 3) ACS universe 4) variables to be grouped 5) summary estimate variable
vars <- list(
             c(name = "renter", alias = "Renter", universe = "Occupied housing units", variable = I(list(c("B25003_003"))), summary = c("B25003_001")), 
             c(name = "under5", alias = "Under 5", universe = "Total population", variable = I(list(c("B01001_003", "B01001_027"))), summary = c("B01001_001")),
             c(name = "noVeh", alias = "No Vehicle", universe = "Occupied housing units", variable = I(list(c("B25044_003", "B25044_010"))), summary = c("B25044_001")),
             c(name = "disabHH", alias = "Disabled", universe = "Households", variable = I(list(c("B22010_003","B22010_006"))), summary = c("B22010_001")),
             c(name = "SglPar", alias = "Single Parent", universe = "Families", variable = I(list(c("B11004_010","B11004_016"))), summary = c("B11004_001")),
             c(name = "PoC", alias = "People of Color", universe = "Total population", variable = I(list(sapply(formatC(c(4:9,12), width = 3, format = "d", flag = "0"), function(x) paste0("B03002_",x)))), summary = c("B03002_001")),  # add in email to Elizabeth
             c(name = "65Alone", alias = "Over 65 Alone", universe = "Households", variable = I(list(c("B11007_003"))), summary = c("B11007_001")),
             c(name = "noHS", alias = "No High School Degree", universe = "Population 25 years and over", variable = I(list(sapply(formatC(2:16, width = 3, format = "d", flag = "0"), function(x) paste0("B15003_",x)))), summary = c("B15003_001")),
             #c(name = "RentHCB", alias = "Rent Burden", universe = "Renter-occupied housing units", variable = I(list(c("B25070_010"))), summary = c("B25070_001")),
             c(name = "MortgageHCB", alias = "Mortage Burden", universe = "Owner-occupied housing units", variable = I(list(c("B25091_011"))), summary = c("B25091_002")), #rephrase in user documentation/ non-mortgage housing units
             c(name = "LEP_HH", alias = "Limited English Proficiency", universe = "Households", variable = I(list(c("C16002_004","C16002_007","C16002_010","C16002_013"))), summary = c("C16002_001")),
             c(name = "B200Pv", alias = "Income to Poverty Ratio", universe = "Population for whom poverty status is determined", variable = I(list(sapply(formatC(2:7, width = 3, format = "d", flag = "0"), function(x) paste0("C17002_",x)))), summary = c("C17002_001")) # change formatC since only 1 table pulled
             )

# for each variable combination (vars) perform the bcdc_get_acs and vulnflag functions and save as a list entry in datalist
datalist <- lapply(vars, function(x) bcdc_get_acs(x) %>% vulnflag())

# convert to single sf object
temp <- do.call(rbind, datalist)
# bind all datalist entries (one for each variable) to main data by row
data <- bind_rows(data, temp)
## remove datalist
#rm(datalist)

# find all missing columns calculated for the indicators
#missing <- names(data)[!names(data) %in% names(temp)]
# fill object with columns and NAs for row binding (must have exact same columns)
#temp <- temp %>% `is.na<-`(missing)
# bind all datalist entries (one for each variable) together by row
#data <- rbind(data, temp)
```

```{r Rent (seperate, because Not Calculated removed from Total)}
renthcb <- get_acs(geography = "block group",
           table = "B25070",
           state = "CA",
           county = bayareacounties,
           year = year,
           geometry = F
           ) %>%
  mutate(alias = "Rent Burden") %>%
  mutate(universe = "Renter-occupied housing units") %>%
  group_by(GEOID) %>% 
  filter(!variable %in% c("B25070_001", "B25070_011")) %>%
  mutate(summary_est = sum(estimate), summary_moe = sqrt(sum(moe^2))) %>%
  filter(variable == "B25070_010") %>%
  mutate(variable = "RentHCB") %>% vulnflag()

data <- rbind(data, renthcb)
```

```{r Not U.S. Citizen (Tract to Block Group)}
# pulling by tract, since data is not available at block group level
notuscitizen <-  get_acs(
          geography = "tract",
          variables = c("B05002_021"),
          state = "CA",
          county = bayareacounties,
          summary_var = "B05002_001",
          year = year,
          geometry = T
          ) %>% 
    mutate(variable = "NoCtz") %>%
    mutate(alias = "Not U.S. Citizen") %>%
    mutate(universe = "Total population") %>% st_transform(26910)

# joining tracts on to empty block groups to create same structure as the block group data
notuscitizen <- st_join(emptyblockgroups, notuscitizen[c("variable", "alias", "estimate", "moe", "summary_est", "summary_moe", "universe")], left_join=T, largest = T) %>% vulnflag() %>% st_drop_geometry()

# bind to main data
data <- rbind(data, notuscitizen)
```

```{r Household Median Income}
hhminc <- vector()

# iterating through each of the 9 counties and pulling seperate AMIs & identifying households with incomes under or that value
for(i in bayareacounties){
    # calculate half of Area Median Income (AMI) on county basis to use in calculating households
    halfAMI <- get_acs(
              geography = "county",
              variables = c("B19013_001"),
              state = "CA",
              county = i,
              year = year,
              geometry = F
              # calculate 50% of the regional median income and save as numeric value and round to nearest 10,000th
              ) %>% summarise(median(estimate, na.rm = T)/2) %>% as.numeric()
    
    # find Census table number that contains value of half Area Median Income (AMI)
    # filter for correct table and extract table entry with upper $ value matching halfAMI
    x <- v18 %>% filter(stringr::str_detect(name, "B19001_")) 
    # grab all table labels
    x <- gsub(",", "", x$label)
    # pull out any numeric values in the table labels
    x <- sapply(regmatches(x, gregexpr("\\d+", x)), function(x) as.numeric(x))
    # determine which upper ranges of the table labels $ amounts are smaller or equal to half AMI
    x <- sapply(x, function(x) tail(unlist(x), n=1) <= halfAMI)

    medianincome <- get_acs(
              geography = "block group",
              # grab all tables in which the upper range is smaller or equal to halfAMI
              variables = sapply(formatC(which(x=="TRUE"), width = 3, format = "d", flag = "0"), function(x) paste0("B19001_",x)),
              state = "CA",
              county = i,
              summary_var = "B19001_001",
              year = year,
              geometry = F
              ) %>%
        mutate(variable = "50MedianAMI") %>%
        mutate(alias = "Under Half Of Median AMI") %>%
        mutate(universe = "Households") %>% ungroup()
    
    # bind together
    hhminc <- rbind(hhminc, medianincome)
}
# calculating percentile thresholds (number of households by county below or equal to half AMI) and flagging for the entire region
hhminc <- hhminc %>% vulnflag 
# bind to main data
data <- rbind(data, hhminc)
```

```{r Combination of Indicators (Housing Cost Burden & Very Low Income)}
# housing cost burdened if rent AND mortgage >50% income
hcb <- data %>% ungroup() %>% filter(variable %in% c("RentHCB","MortgageHCB"))
hcb <- hcb %>% group_by(GEOID, NAME) %>%
  dplyr::summarise(
                    variable = "HCB",
                    alias = "Severe Housing Cost Burden",
                    flag70 = ifelse(sum(flag70) == 2, 1, 0),
                    flag90 = ifelse(sum(flag90) == 2, 1, 0),
                    estimate = NA,
                    moe = NA,
                    pct = NA,
                    pct_moe = NA,
                    pctile70 = NA,
                    pctile90 = NA,
                    summary_est = NA,
                    summary_moe = NA,
                    universe = NA
                  ) %>% ungroup()

# very low income if <0.5 income to poverty ratio AND/OR household income <50% AMI
inc <- data %>% ungroup() %>% filter(variable %in% c("B200Pv","50MedianAMI"))
inc <- inc %>% group_by(GEOID, NAME) %>%
  dplyr::summarise(
                    variable = "VLowInc",
                    alias = "Very Low Income",
                    flag70 = ifelse(sum(flag70) > 0, 1, 0),
                    flag90 = ifelse(sum(flag90) > 0, 1, 0),
                    estimate = NA,
                    moe = NA,
                    pct = NA,
                    pct_moe = NA,
                    pctile70 = NA,
                    pctile90 = NA,
                    summary_est = NA,
                    summary_moe = NA,
                    universe = NA
                  ) %>% ungroup()

data <- rbind(data, hcb)
data <- rbind(data, inc)

# removing individual flagging of the combined indicators to avoid double counting
data <- data %>% group_by(variable) %>% mutate(
  flag70 = case_when(variable %in% c("RentHCB","MortgageHCB","B200Pv","50MedianAMI") ~ NA_real_, TRUE ~ flag70),
  flag90 = case_when(variable %in% c("RentHCB","MortgageHCB","B200Pv","50MedianAMI") ~ NA_real_, TRUE ~ flag90)) %>% ungroup()
```

```{r Block Group Cumulative Flag and Listing Indicators}
# create field summing the number of indicators in the 70th and 90th percentiles
data <- data %>% group_by(GEOID) %>% mutate(socVuln70 = sum(flag70, na.rm = T),
                                            socVuln90 = sum(flag90, na.rm = T)) %>% ungroup()

# create field listing indicators in the 70th and 90th percentiles (omit NA's, since the paste function coerces missing values)
data <- data %>% group_by(GEOID) %>% mutate(ind_70pct = paste(na.omit(alias[flag70>0]), collapse=', '),
                                            ind_90pct = paste(na.omit(alias[flag90>0]), collapse=', ')) %>% ungroup()

# flag low, medium, high, highest social vulnerability
data <- data %>% group_by(GEOID) %>% mutate(socVulnRank = 
  case_when(socVuln70 >= 8 | socVuln90 >= 6 ~ "Highest social vulnerability",
            socVuln70 %in% c(6,7) | socVuln90 %in% c(4,5) ~ "High social vulnerability",
            socVuln70 %in% c(4,5) | socVuln90 == 3 ~ "Moderate social vulnerability",
            TRUE ~ "Low social vulnerability")) %>% ungroup()
```

# Change format to a tidy wide format for use in GIS software
```{r Tidy wide format}
# remove any data entries with no variable
data <- data %>% ungroup() %>% filter(!is.na(variable))
# remove columns that are not useful in pivoting to wide format
data_wide <- data %>% select(-c(summary_est, summary_moe, pctile70, pctile90, alias, universe))
# pivot table to wide format for GIS applications
data_wide <- data_wide %>% tidyr::pivot_wider(names_from = c(variable), values_from = c(estimate, moe, pct, pct_moe, flag70, flag90))
# remove any fields that are completely NA, e.g. pct for summary variables
data_wide <- data_wide %>% select_if(not_any_na <- function(x) any(!is.na(x)))
# reattach geometry (because pivot_wider cannot use sf object) and to have all block groups (even ones without data)
data_wide <- left_join(emptyblockgroups, select(data_wide,-NAME), by="GEOID")
```

# Indicators that are not directly used for vulnerability ranking (some included in combined indicators above)
```{r Supplementary Indicators}
"pct_ForBrn         Population foreign born rate       Double True                                       
pctSpanish          Speak English less than very well and speak Spanish         Double True                                       
pctChinese         Speak English less than very well and speak Chinese         Double True                                       
pctVietnms         Speak English less than very well and speak Vietnamese Double True                                       
pctTagalog          Speak English less than very well and speak Tagalog          Double True                                       
est_Latino           est_Latino           Short     True                                       
MOE_Latino       MOE_Latino       Short     True                                       
pct_Latino           Percent Hispanic or Latino            Double True                                       
est_Black             est_Black             Short     True                                       
MOE_Black         MOE_Black         Short     True                                       
pct_Black             Percent Black or African American            Double True                                       
est_AmIndn       est_AmIndn       Short     True                                       
MOE_AmIndn   MOE_AmIndn   Short     True                                       
pct_AmIndn       Percent American Indian and Alaska Native          Double True                                       
est_Asian            est_Asian            Short     True                                       
MOE_Asian        MOE_Asian        Short     True                                       
pct_Asian            Percent Asian    Double True                                       
est_Island           est_Island           Short     True                                       
MOE_Island       MOE_Island       Short     True                                       
pct_Island           Percent Native Hawaiian and Other Pacific Islander          Double True                                       
est_OthRac        est_OthRac        Short     True                                       
MOE_OthRac     MOE_OthRac     Short     True                                       
pct_OthRac        Percent other race           Double True                                       
est_TwoRac       est_TwoRac       Short     True                                       
MOE_TwoRac    MOE_TwoRac    Short     True                                       
pct_TwoRac       Percent two or more races           Double True                                       
pctUnder10        Percent population under 10       Double True                                       
pctUnder18        Percent population under 18       Double True   
"

# Tract Supplementary Variables (joined to block group level)
# listing of all BCDC variable combinations: 1) abbreviated name 2) common variable name 3) ACS universe 4) variables to be grouped 5) summary estimate variable
vars <- list(
             c(name = "ForBrn", alias = "Foreign Born", universe = "Total population", variable = I(list(c("B05002_013"))), summary = c("B05002_001")),
             c(name = "LEP_Spanish", alias = "LEP Spanish", universe = "Population 5 years and older", variable = I(list(c("C16001_005"))), summary = c("C16001_001")),
             c(name = "LEP_Chinese", alias = "LEP Chinese", universe = "Population 5 years and older", variable = I(list(c("C16001_023"))), summary = c("C16001_001")),
             c(name = "LEP_Vietnms", alias = "LEP Vietnms", universe = "Population 5 years and older", variable = I(list(c("C16001_026"))), summary = c("C16001_001")),
             c(name = "LEP_Tagalog", alias = "LEP Tagalog", universe = "Population 5 years and older", variable = I(list(c("C16001_029"))), summary = c("C16001_001"))
              )

datalist <- lapply(vars, function(x) bcdc_get_acs(x, geography = "tract") %>% vulnflag())
# joining tracts on to empty block groups to create same structure as the block group data
#datalist <- lapply(datalist, function(x) st_join(emptyblockgroups, x[c("variable", "alias", "estimate", "moe", "summary_est", "summary_moe", "universe", "pct", "pct_moe")], left_join= T, largest = T))
datalist <- lapply(datalist, function(x) left_join(emptyblockgroups, x[c("GEOID", "variable", "alias", "estimate", "moe", "summary_est", "summary_moe", "universe", "pct", "pct_moe")], by = c("TRACTID"="GEOID")))
# bind all datalist entries (one for each variable) together by row
datalist <- do.call(rbind, datalist)
# remove any data entries with no variable
datalist <- datalist %>% ungroup() %>% filter(!is.na(variable))
# remove columns that are not useful in pivoting to wide format and TRACTID, because it already exists in main dataset
datalist <- datalist %>% select(-c(summary_est, summary_moe, alias, universe, TRACTID))
# remove geometry for pivot_wider
datalist <- datalist %>% st_set_geometry(NULL)
# pivot table to wide format for GIS applications
datalist <- datalist %>% tidyr::pivot_wider(names_from = c(variable), values_from = c(estimate, moe, pct, pct_moe))
# left join onto main data
data_wide <- left_join(data_wide, select(datalist,-NAME), by="GEOID")

# Block Group Supplementary Variables
# listing of all BCDC variable combinations: 1) abbreviated name 2) common variable name 3) ACS universe 4) variables to be grouped 5) summary estimate variable
vars <- list(
             c(name = "Latino", alias = "Latino", universe = "Total population", variable = I(list(c("B03002_012"))), summary = c("B03002_001")),
             c(name = "Black", alias = "Black", universe = "Total population", variable = I(list(c("B03002_004", "B03002_014"))), summary = c("B03002_001")),
             c(name = "AmIndn", alias = "American Indian and Alaska Native", universe = "Total population", variable = I(list(c("B03002_005", "B03002_015"))), summary = c("B03002_001")),
             c(name = "Asian", alias = "Asian", universe = "Total population", variable = I(list(c("B03002_006", "B03002_016"))), summary = c("B03002_001")),
             c(name = "Island", alias = "Native Hawaiian and Other Pacific Islander", universe = "Total population", variable = I(list(c("B03002_007", "B03002_017"))), summary = c("B03002_001")),
             c(name = "OthRac", alias = "Other race", universe = "Total population", variable = I(list(c("B03002_008", "B03002_018"))), summary = c("B03002_001")),
             c(name = "TwoRac", alias = "Two or more races", universe = "Total population", variable = I(list(c("B03002_009", "B03002_019"))), summary = c("B03002_001")),
             c(name = "Under10", alias = "Population under 10", universe = "Total population", variable = I(list(c("B01001_003", "B01001_004", "B01001_027", "B01001_028"))), summary = c("B01001_001")),
             c(name = "Under18", alias = "Population under 18", universe = "Total population", variable = I(list(c("B01001_003", "B01001_004", "B01001_005", "B01001_006", "B01001_027", "B01001_028", "B01001_029", "B01001_030"))), summary = c("B01001_001"))
             )

# for each variable combination (vars) perform the bcdc_get_acs and vulnflag functions and save as a list entry in datalist
datalist <- lapply(vars, function(x) bcdc_get_acs(x) %>% vulnflag())
# bind all datalist entries (one for each variable) together by row
datalist <- do.call(rbind, datalist)
# remove any data entries with no variable
datalist <- datalist %>% ungroup() %>% filter(!is.na(variable))
# remove columns that are not useful in pivoting to wide format
datalist <- datalist %>% select(-c(summary_est, summary_moe, pctile70, pctile90, alias, universe, flag70, flag90))
# remove geometry for pivot table
#datalist<- datalist %>% st_set_geometry(NULL)
# pivot table to wide format for GIS applications
datalist <- datalist %>% tidyr::pivot_wider(names_from = c(variable), values_from = c(estimate, moe, pct, pct_moe))
# left join onto main data
data_wide <- left_join(data_wide, select(datalist,-NAME), by="GEOID")
```

# Add Supplementary Non-ACS Data
```{r Download Supplimentary Data}
destfile <- "./Inputs/ces4.xlsx"
fileURL <- "https://oehha.ca.gov/media/downloads/calenviroscreen/document/ces3results.xlsx"
if (!file.exists(destfile)) {
    download(fileURL, destfile, mode="wb") }
ces <- readxl::read_xlsx(destfile)
ces$`Census Tract` <- str_pad(ces$`Census Tract`, width=11, side="left", pad="0")
ces <- ces %>% select(c(CES4_pctl = "CES 4.0 Percentile", Clean_pctl = "Cleanup Sites Pctl", GW_pctl = "Groundwater Threats Pctl" , Haz_pct = "Haz. Waste Pctl", IWB_pctl = "Imp. Water Bodies Pctl", Solid_pctl = "Solid Waste Pctl",  TRACTID = "Census Tract"))

destfile <- "./Inputs/mtccoc.csv"
fileURL <- "https://opendata.arcgis.com/datasets/1501fe1552414d569ca747e0e23628ff_0.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D"
if (!file.exists(destfile)) {
    download(fileURL, destfile, mode="wb") }
mtc <- read_csv(destfile)
mtc <- mtc %>% select(TRACTID = "geoid", MTC_CoC_2018 = "coc_class")

destfile <- "./Inputs/udp.csv"
fileURL <- "https://www.urbandisplacement.org/sites/default/files/images/udp_2017results.csv"
if (!file.exists(destfile)) {
    download(fileURL, destfile, mode="wb") }
udp <- read_csv(destfile)
udp$geo_fips <- str_pad(udp$geo_fips, width=11, side="left", pad="0")
udp <- udp %>% select(TRACTID = "geo_fips", displcType = "Typology")

pdas <- sf::st_read("Inputs\\Priority_Development_Areas_current.shp")
# setting CRS to be same the same as main data
pdas <- st_transform(pdas, 26910)
pdas <- pdas %>% select(PDA_Name = "name", PDA_ID = "joinkey")
# make valid fixes geometry issue (self-intersection)
pdas <- st_make_valid(pdas)
```

```{r Join Supplimentary Data}
# left joining data set by unique TRACT IDs
data_wide <- left_join(data_wide, mtc, by = "TRACTID")
data_wide <- left_join(data_wide, udp, by = "TRACTID")
data_wide <- left_join(data_wide, ces, by = "TRACTID")
# considering PDAs with largest overlap with each block group to avoid issue where block groups are in multiple PDAs
data_wide <- st_transform(data_wide, 26910)
data_wide <- st_join(data_wide, pdas, left = T, largest = T)
```

```{r CalEnviroScreen 3.0 Indicator List}
# calculate number of CalEnviroScreen 3.0 indicators above 70th and 90th percentile and the contamination rank
data_wide <- data_wide %>% group_by(GEOID) %>%
  mutate(
  contam70 = sum(c(!!!syms(names(ces[2:6]))) >= 70, na.rm = T),
  contam90 = sum(c(!!!syms(names(ces[2:6]))) >= 90, na.rm = T)
  ) %>%
  mutate(contamVulnRank = 
    case_when(CES4_pctl >= 90 | contam90 >= 4 ~ "Highest contamination vulnerability",
            CES4_pctl >= 80 | contam70 >= 5 ~ "High contamination vulnerability",
            CES4_pctl >= 70 | contam70 >= 4 ~ "Moderate contamination vulnerability",
            TRUE ~ "Lower contamination vulnerability")
        ) %>% ungroup()

data_wide <- data_wide %>% group_by(GEOID) %>%
  mutate(
    contam_ind_70pct = 
      paste0(na.omit(c(
        ifelse(Clean_pctl >= 70, paste0("Cleanup Sites"), NA),
        ifelse(GW_pctl >= 70, paste0("Groundwater Threats"), NA),
        ifelse(Haz_pct >= 70, paste0("Hazardous Waste"), NA),
        ifelse(IWB_pctl >= 70, paste0("Impaired Water Bodies"), NA),
        ifelse(Solid_pctl >= 70, paste0("Solid Waste Sites"), NA)
        )), collapse = ", "),
    contam_ind_90pct = 
      paste0(na.omit(c(
        ifelse(Clean_pctl >= 90, paste0("Cleanup Sites"), NA),
        ifelse(GW_pctl >= 90, paste0("Groundwater Threats"), NA),
        ifelse(Haz_pct >= 90, paste0("Hazardous Waste"), NA),
        ifelse(IWB_pctl >= 90, paste0("Impaired Water Bodies"), NA),
        ifelse(Solid_pctl >= 90, paste0("Solid Waste Sites"), NA)
        )), collapse = ", ")
  ) %>% ungroup()

```

# Adding Block Group Centroids for leaflet and other GIS calculations
```{r Centroids for shiny leaflet}
# centroids should be calculated in projected coordinate system, but leaflet needs lat long coordinates
centroids <- data_wide %>% ungroup() %>% st_transform(26910) %>% select(geometry) %>% st_centroid(geometry) %>% st_transform(4236)
data_wide$centroid_lng <- st_coordinates(centroids)[,1]
data_wide$centroid_lat <- st_coordinates(centroids)[,2]
```

# Add parcel-based Exposure Data of Residential Units and Job Spaces in 2010 and 2040 projection (.gdb calculated in ArcGIS pro, located in Inputs)
```{r Exposure Data}
layers <- sf::st_layers("Inputs\\Summarized_SLR_Parcels.gdb")
#read in parcel data, but ignore unnecessary fields
parcels <- lapply(layers$name, function(x) sf::st_read(dsn = "Inputs\\Summarized_SLR_Parcels.gdb", layer = x) %>% st_drop_geometry() %>% select(-c("Shape_Length","Shape_Area", "SUM_Area_ACRES", "NAME"))) 
#rename list elements 
names(parcels) <- layers$name
#sort list elements based on TWL scenario
parcels <- parcels[c(2:10,1,11:14)]
#rename columns to be unique for each TWL scenario after joining
parcels <- mapply(x = parcels, i = names(parcels), function(x,i) {
  names(x)[2:5] <- paste(names(x)[2:5], "_",sub('.*\\_', '', names(parcels[i])), sep="")
  return(x)
  }, SIMPLIFY = F)
#GEOID as factor to suppress warning during following join
data_wide$GEOID <- as.factor(data_wide$GEOID)
#combine all parcel TWL scenarios
parcels <- reduce(parcels, merge)
#join to main data set
data_wide <- left_join(data_wide, parcels, by = "GEOID")
```

# Blockgroups with totPop = 0, set to "Not Calculated" Social Vulnerability Rank
```{r Not Calculated for 0 Population}
#data_wide <- data_wide %>% mutate(socVulnRank=replace(socVulnRank, estimate_totPop == 0, "Not Calculated"))
data_wide <- data_wide %>% mutate(socVulnRank=replace(socVulnRank, estimate_totPop < 100 | estimate_totHH < 100, "Not Calculated"))
```

# tidycensus uses EPSG: 4263 (Google Pseudo-Mercator), transforming output to EPSG: 26910 
```{r Save Data}
# read in pre-calculated empty block groups with erased water layer
emptyblockgroups_nowater <- sf::st_read("./Inputs/bg_nowater.shp")
# make all feature valid (self-intersections etc.)
emptyblockgroups_nowater <- st_make_valid(emptyblockgroups_nowater)
# remove geometry for pivot table
data_wide<- data_wide %>% st_set_geometry(NULL)
# left join onto detailed block group shapes
data_wide <- left_join(emptyblockgroups_nowater, select(data_wide,-NAME), by="GEOID")

saveRDS(data_wide, "Outputs/data")

dir.create(file.path(getwd(), "Outputs"), showWarnings = FALSE)

# write to .csv data_wide WIDE
st_write(data_wide, paste0(getwd(),"/Outputs/CommunityVulnerability_", paste0("ACS_", year-4, "_", year, "_"), format(as.Date(Sys.Date()), "%d_%m_%Y"),"_WIDE",".csv"))
# reattach geometry to export data LONG
data <- left_join(emptyblockgroups, select(data,-NAME), by="GEOID")
st_write(data, paste0(getwd(),"/Outputs/CommunityVulnerability_", paste0("ACS_", year-4, "_", year, "_"),format(as.Date(Sys.Date()), "%d_%m_%Y"),"_LONG",".csv"))


# write to .sthp as simple feature
#st_write(data, paste0(getwd(),"/Outputs/CommunityVulnerability_SF_",format(as.Date(Sys.Date()), "%d_%m_%Y"),".shp"))

# write to .shp as ESRI feature, transform to EPSG Code: 26910
arcgisbinding::arc.write(paste0(getwd(),"/Outputs/final/CommunityVulnerability_Arc.gdb/CommunityVulnerability_Arc_", paste0("ACS_", year-4, "_", year, "_"),format(as.Date(Sys.Date()), "%d_%m_%Y")), st_transform(data_wide, 26910), shape_info=list(type='Polygon',WKID=26910))
```

# To Do
# Add field name abbreviations to user documentation

# Reticulate to use ArcPy to attach field aliases (if completed needs to be moved before arc.write export)
```{r reticulate ArcPy to add Alias to Fields}
# Bridging R and Python
library(reticulate)
# Reading in table of field names and their aliases
aliases <- readxl::read_excel(".\\Inputs\\CommunityVulnerability_FieldNames_Alias.xlsx")
# Using ArcGIS Pro's Python (this is the standard directory, must be manually set otherwise)
use_python("C:/Program Files/ArcGIS/Pro/bin/Python/envs/arcgispro-py3")
# Import the arcpy module
arcpy <- import('arcpy')

# Read in the output feature class
fc <- ".\\Outputs\\CommunityVulnerability_Arc.gdb\\CommunityVulnerability_Arc_ACS_2014_2018_09_07_2020"
# List the field objects
fields <- arcpy$ListFields(fc)

# save the names of all arc field objects
datafields <- c()
for(f in fields){
              datafields <- c(datafields, f$name) }
aliases$datafields <- datafields

# remove ObjectID, Shape, ShapeArea, ShapeLength, since they cannot be edited
fields <- fields[-c(1,2, length(fields)-1, length(fields))]

# check for where field name is equal to field name in alias list and assign that alias
for(field in fields){ #loop through each field
        arcpy$AlterField_management(fc, field$name, "", aliases$Alias[aliases$`Field Name` == field$name]) }

#name printing
#for(f in fields){ print(f$name) }
#for(f in fields){ print(f$aliasName) }
```

# Visualization
```{r Visualize with Leaflet, eval=F}
# read in CommunityVulnerability.Rmd Output
output <- data_wide
# Create interactive leaflet of Vulnerable Communities data
mapview(output, zcol = "socVulnRank", alpha=0, legend = TRUE)
#mapview(vc_nowater %>% filter(variable == "totalpopulation"), zcol = "estimate", legend = TRUE)
```

```{r symbology & new columns on difference between 2020 and 2023 socVulnRank and contamVulnRank}
#This section was added late in the 2023 update process and wasn't able to be fully integrated in the script. This section creates a new table that needs to be manually joined to the .gdb in arcpro after running. If new staff running this code has capacity, they can integrate this code BEFORE LINE 639: # write to .shp as ESRI feature, transform to EPSG Code: 26910 so that it is integrated into the final .gdb without further steps. 

#final new column is soc_diff_val and contam_diff_val, if positive means got "better", and if negative got "worse"
# Comparing socVulnRank 2020 and 2023
destfile <- "./Inputs/CommunityVulnerability_ACS_2012_2016_22_07_2020_WIDE.csv"
df20 <- read.csv(destfile)
destfile2 <- "./Inputs/CommunityVulnerability_ACS_2017_2021_04_05_2023_WIDE.csv"
df23 <- read.csv(destfile2)

# remove all but socVulnRank and contamVulnRank from 2020
df20 <- df20 %>%
  select(GEOID, NAME, socVulnRank, contamVulnRank) %>%
  mutate(socVulnRank2020 = socVulnRank, contamVulnRank2020 = contamVulnRank) %>%
 # mutate(GEOID = as.character(df20$GEOID)) %>%
  select(GEOID, socVulnRank2020, contamVulnRank2020)
df23 <- df23 %>%
  select(GEOID, NAME, socVulnRank, contamVulnRank)

# join to 2023 as RankCompare
df <- left_join(df23, df20, by = "GEOID")


# convert soc and contam categories to values to find a difference between updates
df_diff <- df #%>% 
  #mutate(diff = if_else(socVulnRank != socVulnRank20, "Y", "N"))
df_diff$socVulnRank_value <- plyr::revalue(df_diff$socVulnRank,
                                     c("Low social vulnerability"= "1", "Moderate social vulnerability"="2", "High social vulnerability"="3", "Highest social vulnerability"="4"))

df_diff$socVulnRank2020_value <- plyr::revalue(df_diff$socVulnRank2020,
                                           c("Low social vulnerability"= "1", "Moderate social vulnerability"="2", "High social vulnerability"="3", "Highest social vulnerability"="4"))
df_diff$soc_diff_val <- as.numeric(df_diff$socVulnRank_value) - as.numeric(df_diff$socVulnRank2020_value)

df_diff$contamVulnRank_value <- plyr::revalue(df_diff$contamVulnRank,
                                     c("Lower contamination vulnerability"= "1", "Moderate contamination vulnerability"="2", "High contamination vulnerability"="3", "Highest contamination vulnerability"="4"))

df_diff$contamVulnRank2020_value <- plyr::revalue(df_diff$contamVulnRank2020,
                                           c("Lower contamination vulnerability"= "1", "Moderate contamination vulnerability"="2", "High contamination vulnerability"="3", "Highest contamination vulnerability"="4"))
df_diff$contam_diff_val <- as.numeric(df_diff$contamVulnRank_value) - as.numeric(df_diff$contamVulnRank2020_value)

#Create symbology field for ARCGIS - None, Social, Contamination, Both
df_diff <- df_diff %>%
 mutate(combined_vulnerability = case_when(
   socVulnRank == "NA" & contamVulnRank == "NA" ~ "Low/Not Calculated",
   socVulnRank == "NA" & contamVulnRank == "Lower contamination vulnerability" ~ "Low/Not Calculated",
   socVulnRank == "Low social vulnerability" & contamVulnRank == "NA" ~ "Low/Not Calculated",
   socVulnRank == "Moderate social vulnerability" & contamVulnRank == "Lower contamination vulnerability" ~ "Social",
   socVulnRank == "High social vulnerability" & contamVulnRank == "Lower contamination vulnerability" ~ "Social",
   socVulnRank == "Highest social vulnerability" & contamVulnRank == "Lower contamination vulnerability" ~ "Social",
   socVulnRank == "Low social vulnerability" & contamVulnRank == "Moderate contamination vulnerability" ~ "Contamination",
   socVulnRank == "Low social vulnerability" & contamVulnRank == "High contamination vulnerability" ~ "Contamination",
   socVulnRank == "Low social vulnerability" & contamVulnRank == "Highest contamination vulnerability" ~ "Contamination",
   socVulnRank == "Moderate social vulnerability" & contamVulnRank == "Moderate contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "Moderate social vulnerability" & contamVulnRank == "High contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "Moderate social vulnerability" & contamVulnRank == "Highest contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "High social vulnerability" & contamVulnRank == "Moderate contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "Highest social vulnerability" & contamVulnRank == "Moderate contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "High social vulnerability" & contamVulnRank == "High contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "High social vulnerability" & contamVulnRank == "Highest contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "Highest social vulnerability" & contamVulnRank == "High contamination vulnerability" ~ "Social and Contamination",
   socVulnRank == "Highest social vulnerability" & contamVulnRank == "Highest contamination vulnerability" ~ "Social and Contamination"
 ))

#df23 join and switch to data_wide
df_diff <- df_diff %>%
  select(GEOID, NAME, socVulnRank2020, contamVulnRank2020, soc_diff_val, contam_diff_val, combined_vulnerability)
df_diff$GEOID <- paste0("0", df_diff$GEOID)
df_diff$GEOID <- as.character(df_diff$GEOID)


#df_diff$GEOID = paste(rep(0, df_diff$GEOID), df_diff$GEOID, sep = "")

#data_wide_atmpt <- st_join(data_wide, df_diff, by = "GEOID")
#data_wide <- data_wide %>%
  #left_join(df_diff, by = "NAME")
write.csv(df_diff, "update_diffs_and_symbology_fields.csv")

```

